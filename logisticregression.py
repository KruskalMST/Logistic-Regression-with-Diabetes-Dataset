# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jEYr3DP19-uP-8gngXaTo6PyIZiQLVOq

Single Quantitative Predictor
"""

#(a)
data = read.csv('Short_Project_3_data.csv')

data$diagnosis[data$diagnosis=='B'] <- 0
data$diagnosis[data$diagnosis=='M'] <- 1
names(data)

data$diagnosis <- as.numeric(diagnosis)
data$radius_mean <- as.numeric(radius_mean)

glm.fit = glm(data$diagnosis ~ data$radius_mean, family = binomial)
summary(glm.fit)

"""(b) The slope coefficient is positive, so an increase in radius_mean is associated with an increase in the probability of a malignant diagnosis. A 1 unit increase in radius_mean results in a 1.03359 increase in logit(pi) of malignant diagnosis to benign diagnosis.

The odds ratio (probability of the diagnosis being malignant over the probability of the diagnosis being benign) at any given value of X (radius_mean) is pi/(1-pi) where pi is equal to (e^(-15.24587+1.03359X))/(1+e^(-15.24587+1.03359X)). On average, a person with x radius_mean will have pi probability of having malignant cancer.

When we increase the radius_mean by 1, the ratio of the new odds to the old odds is e^(1.03359).

H0: Radius_mean is not a useful predictor in the model.

Ha: Radius_mean is a useful predictor in the model.

The p-value is < 2e-16, which is smaller than a significance level of 0.05, so we reject the null hypothesis. Radius_mean is a useful predictor in the model.
"""

#before interpreting, need to exponentiate the slope coefficient
round(exp(coefficients(glm.fit)[2]), 2)

"""The odds ratio for someone with malignant cancer is 2.81 relative to someone with benign cancer.

CI for slope: B_1 +- z*SE(B1)

1.03359 +/- 1.96(0.09311)
"""

#(c)
exp(confint(glm.fit, level = 0.95))
exp(1.03359 - 1.96*0.09311)
exp(1.03359 + 1.96*0.09311)

"""Since 1 is not in the interval for odds ratio, there is statistically significant evidence that there is a higher proportion of malignant cancer (success, 1) to beign cancer (failure, 0).

We are 95% confident that the slope of the logistic regression will be between 2.34 and 3.37 (odds of malignant cancer increase by a factor of somewhere between 2.34 and 3.37 for every 1 unit increase in radius_mean).
"""

#(d)
#p(x) = e^(B0+B1X)/(1+e^(B0+B1X))
cat("When X (radius_mean) is 10, the probability of malignant is", (exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*10))/
  (1+exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*10)), "\n")
cat("When X (radius_mean) is 15, the probability of malignant is", (exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*15))/
  (1+exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*15)), "\n")
cat("When X (radius_mean) is 20, the probability of malignant is", (exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*20))/
  (1+exp(glm.fit$coefficients[1] + glm.fit$coefficients[2]*20)))

"""When we increase the radius_mean, the probability of malignant increases. When we have a radius_mean of around 15, the probability of malignant is about 56%. When we have a radius_mean of around 10, the probability of malignant is less than 1%. When we have a radius_mean of around 20, the probability of malignant is almost 100%. There is a dramatic increase in the probability of malignant as the radius_mean increases."""

#(e)
library(ggplot2)

# Plot Predicted data and original data points
ggplot(data, aes(x=radius_mean, y=diagnosis)) + geom_point() +
  stat_smooth(method="glm", color="blue", se=FALSE, method.args =
    list(family=binomial))

"""The graph is s-shaped. There are a couple data points located at 1.00 and 0.00. There is a slightly longer tail at the top compared to the bottom, so there is some more data at the top."""

#(f)
Gtest <- function(model){
  if((summary(model)$family[1] == "binomial")){
    n <- length(anova(model)[,1])
    null.deviance <- anova(model)[1,4]
    residual.deviance <- anova(model)[n,4]
    null.df <- anova(model)[1,3]
    residual.df <- anova(model)[n,3]

    G <- null.deviance - residual.deviance
    df <- null.df - residual.df
    p <- pchisq(G, df, lower.tail=F)

    cat("G =", G, "DF =", df, "P-value =", p)
  }
  else{
    stop("This is not a logistic model!")
  }
}

Gtest(glm.fit)
#the G statistic is the null deviance - residual deviance

"""H0: The observed results match with expected/theoretical results and there is no significant difference between the two.

Ha: The observed results do not match with expected/theoretical results.

The p-value 1.192267*10^-93 is smaller than a signficance level of 0.05, so we reject the null hypothesis. The observed results do no match with the expected results. Thus, our results are statistically significant and the model is helpful.

H0: B1 = 0
log(pi/(1-pi))=B0 Same odds for all X

Ha: B1 !=0
log(pi/(1-pi))=B0 Odds are linear function of X

t.s. = G = -2ln(L0) - (-2 ln(L1))

Multiple predictors
"""

#(a)
#test different models
#glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$texture_mean, family = binomial)
#summary(glm.fit2)

#glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$perimeter_mean, family = binomial)
#summary(glm.fit2)

#glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$area_mean, family = binomial)
#summary(glm.fit2)

#glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$compactness_mean, family = binomial)
#summary(glm.fit2)

glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$concavity_mean, family = binomial)
summary(glm.fit2)

#glm.fit2 = glm(data$diagnosis ~ data$radius_mean+data$compactness_mean+data$concavity_mean, family = binomial)
#summary(glm.fit2)

"""We chose to look at two predictors (radius_mean and another label) together in the model, and we looked for the predictor with the smallest p-value. We also tested a model with radius_mean and two other predictors with that resulted in the smallest p-values. We found that concavity_mean resulted in the smallest p-value. So, we chose the model with the two predictors radius_mean and concavity_mean."""

#(b)

#calculating the typical values using median
median(data$radius_mean)
median(data$concavity_mean)

#p(x) = e^(B0+B1X + B2X2)/(1+e^(B0+B1X + B2X2))
cat("When X (radius_mean) is 13.37 and X2 (concavity_mean) is 0.06154, the probability of malignant is", (exp(glm.fit2$coefficients[1] + glm.fit2$coefficients[2]*13.37 + glm.fit2$coefficients[3]*0.06154))/
  (1+exp(glm.fit2$coefficients[1] + glm.fit2$coefficients[2]*13.37 + glm.fit2$coefficients[3]*0.06154)), "\n")

"""(c)

H0: Radius_mean is not a useful predictor in the model.

Ha: Radius_mean is a useful predictor in the model.

The p-value is < 2e-16, which is smaller than a significance level of 0.05. So, we reject the null hypothesis. Radius_mean is a useful predictor in the model.

H0: Concavity_mean is not a useful predictor in the model.

Ha: Concavity_mean is a useful predictor in the model.

The p-value is 1.28e-15, which is smaller than a significance level of 0.05. So, we reject the null hypothesis. Concavity_mean is a useful predictor in the model.

Prediction table
"""

#single model
n <- 20
accuracy <- c()
thresholds <- c()

for (i in 0:n){
  threshold <- i/n
  PredictMalignant <- ifelse(data$diagnosis >= threshold, 1, 0)
  accuracy[i] <- (addmargins(table(data$radius_mean, PredictMalignant))[1,1] +
    addmargins(table(data$radius_mean, PredictMalignant))[2, 2]) /
      length(PredictMalignant)
  thresholds[i] <- i/n
}

predict = fitted(glm.fit)
success = predict>0.5 #TRUE or FALSE for predicted probabilities
actual = data$diagnosis>0.5 #TRUE or FALSE for actual probabilities

PredictedSuccess = sum(success==TRUE)
PredictedFailure = sum(success==FALSE)

ActualSuccess = sum(data$diagnosis==1)
ActualFailure = sum(data$diagnosis==0)

correctsuccess = sum((data$diagnosis==1) & (success==TRUE))
falsesuccess = sum((data$diagnosis==0) & (success==TRUE))
correctfailure = sum((data$diagnosis==0) & (success==FALSE))
falsefailure = sum((data$diagnosis==1) & (success==FALSE))

cat('true success',correctsuccess, '\n')
cat('false success', falsesuccess, '\n')
cat('true failure', correctfailure, '\n')
cat('false failure', falsefailure)

table(success, actual)

correctlypredicted = (correctsuccess+correctfailure)/(correctsuccess+falsesuccess+correctfailure+falsefailure)
correctlypredicted

"""(d) Approximately 87.87% were correctly predicted, so there were not too many cases that were misclassified.

https://docs.google.com/presentation/d/1N9HYa8nbzcfFMDACiCDOEtEXEcGa23x1yYdOuneXPXs/edit?usp=sharing

Diabetes dataset from Kaggle website on last slide.
"""